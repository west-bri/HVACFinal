{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fcc72e2",
   "metadata": {},
   "source": [
    "## **DS5110 Final Project - HVAC**\n",
    "### The goal of this project is to find out which Terminal Units (TUs) are connected to which Rooftop Units (RTUs) in a building, using data science techniques.\n",
    "\n",
    "### **Author:** Bini Chandra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d51239",
   "metadata": {},
   "source": [
    "* **Load TU and RTU Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70879361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded RTU Files:\n",
      "RTU_1.csv       → (4871, 35)\n",
      "RTU_2.csv       → (4873, 35)\n",
      "RTU_3.csv       → (4873, 22)\n",
      "\n",
      "Loaded TU Files:\n",
      "A.csv           → (4818, 23)\n",
      "AA.csv          → (4816, 26)\n",
      "B.csv           → (4818, 24)\n",
      "BB.csv          → (4816, 27)\n",
      "C.csv           → (4818, 24)\n",
      "CC.csv          → (4816, 27)\n",
      "D.csv           → (4818, 24)\n",
      "DD.csv          → (4816, 26)\n",
      "E.csv           → (4818, 24)\n",
      "EE.csv          → (4816, 25)\n",
      "F.csv           → (4818, 25)\n",
      "FF.csv          → (4816, 26)\n",
      "G.csv           → (4818, 25)\n",
      "GG.csv          → (4816, 26)\n",
      "H.csv           → (4818, 25)\n",
      "HH.csv          → (4816, 26)\n",
      "I.csv           → (4818, 26)\n",
      "II.csv          → (4816, 26)\n",
      "J.csv           → (4818, 26)\n",
      "JJ.csv          → (4816, 26)\n",
      "K.csv           → (4818, 26)\n",
      "KK.csv          → (4816, 23)\n",
      "L.csv           → (4818, 26)\n",
      "LL.csv          → (4816, 23)\n",
      "M.csv           → (4818, 26)\n",
      "MM.csv          → (4816, 23)\n",
      "N.csv           → (4818, 26)\n",
      "NN.csv          → (4816, 23)\n",
      "O.csv           → (4818, 26)\n",
      "OO.csv          → (4816, 23)\n",
      "P.csv           → (4818, 25)\n",
      "PP.csv          → (4816, 23)\n",
      "Q.csv           → (4818, 26)\n",
      "QQ.csv          → (4817, 23)\n",
      "R.csv           → (4818, 26)\n",
      "RR.csv          → (4818, 23)\n",
      "S.csv           → (4818, 25)\n",
      "SS.csv          → (4818, 23)\n",
      "T.csv           → (4818, 23)\n",
      "TT.csv          → (4818, 23)\n",
      "U.csv           → (4818, 24)\n",
      "UU.csv          → (4818, 23)\n",
      "V.csv           → (4818, 24)\n",
      "W.csv           → (4818, 23)\n",
      "X.csv           → (4818, 23)\n",
      "Y.csv           → (4818, 24)\n",
      "Z.csv           → (4818, 24)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Folder setup\n",
    "tu_path = \"./data/terminalUnits/\"          # TU files folder\n",
    "rtu_path = \"./data/roofTopUnits/\"          # RTU files folder\n",
    "\n",
    "# Clean and save\n",
    "cleaned_tu_data = {}\n",
    "os.makedirs(\"cleaned_data/cleaned_TUs\", exist_ok=True)\n",
    "cleaned_rtu_data = {}\n",
    "os.makedirs(\"cleaned_data/cleaned_RTUs\", exist_ok=True)\n",
    "\n",
    "#Load all 3 RTU files\n",
    "print(\"Loaded RTU Files:\")\n",
    "rtu_data = {}\n",
    "for file in sorted(os.listdir(rtu_path)):\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(rtu_path, file))\n",
    "        rtu_data[file] = df\n",
    "        print(f\"{file:<15} → {df.shape}\")\n",
    "\n",
    "#Load all 47 TU files\n",
    "print(\"\\nLoaded TU Files:\")\n",
    "tu_data = {}\n",
    "for file in sorted(os.listdir(tu_path)):\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(tu_path, file))\n",
    "        tu_data[file] = df\n",
    "        print(f\"{file:<15} → {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777c35c",
   "metadata": {},
   "source": [
    "\n",
    "**Observations:**\n",
    "\n",
    "3 RTU files: RTU_1 and RTU_2 have 35 columns. RTU_3 has only 22 columns (less informative → probably the unconnected one)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b49ee4",
   "metadata": {},
   "source": [
    "* **Drop client-specified columns and forward-fill the setpoints**\n",
    "    \n",
    "\n",
    "    As per client, we can drop Air_Flow_Diff, Room_Temperature_Diff, VAV_Temperature_Diff, oppMode, SaTemp, SaTmp, SuplFanCmd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02474918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned A.csv           → (4818, 18)\n",
      "Cleaned AA.csv          → (4816, 21)\n",
      "Cleaned B.csv           → (4818, 19)\n",
      "Cleaned BB.csv          → (4816, 22)\n",
      "Cleaned C.csv           → (4818, 19)\n",
      "Cleaned CC.csv          → (4816, 22)\n",
      "Cleaned D.csv           → (4818, 19)\n",
      "Cleaned DD.csv          → (4816, 21)\n",
      "Cleaned E.csv           → (4818, 19)\n",
      "Cleaned EE.csv          → (4816, 20)\n",
      "Cleaned F.csv           → (4818, 20)\n",
      "Cleaned FF.csv          → (4816, 21)\n",
      "Cleaned G.csv           → (4818, 20)\n",
      "Cleaned GG.csv          → (4816, 21)\n",
      "Cleaned H.csv           → (4818, 20)\n",
      "Cleaned HH.csv          → (4816, 21)\n",
      "Cleaned I.csv           → (4818, 21)\n",
      "Cleaned II.csv          → (4816, 21)\n",
      "Cleaned J.csv           → (4818, 21)\n",
      "Cleaned JJ.csv          → (4816, 21)\n",
      "Cleaned K.csv           → (4818, 21)\n",
      "Cleaned KK.csv          → (4816, 18)\n",
      "Cleaned L.csv           → (4818, 21)\n",
      "Cleaned LL.csv          → (4816, 18)\n",
      "Cleaned M.csv           → (4818, 21)\n",
      "Cleaned MM.csv          → (4816, 18)\n",
      "Cleaned N.csv           → (4818, 21)\n",
      "Cleaned NN.csv          → (4816, 18)\n",
      "Cleaned O.csv           → (4818, 21)\n",
      "Cleaned OO.csv          → (4816, 18)\n",
      "Cleaned P.csv           → (4818, 20)\n",
      "Cleaned PP.csv          → (4816, 18)\n",
      "Cleaned Q.csv           → (4818, 21)\n",
      "Cleaned QQ.csv          → (4817, 18)\n",
      "Cleaned R.csv           → (4818, 21)\n",
      "Cleaned RR.csv          → (4818, 18)\n",
      "Cleaned S.csv           → (4818, 20)\n",
      "Cleaned SS.csv          → (4818, 18)\n",
      "Cleaned T.csv           → (4818, 18)\n",
      "Cleaned TT.csv          → (4818, 18)\n",
      "Cleaned U.csv           → (4818, 19)\n",
      "Cleaned UU.csv          → (4818, 18)\n",
      "Cleaned V.csv           → (4818, 19)\n",
      "Cleaned W.csv           → (4818, 18)\n",
      "Cleaned X.csv           → (4818, 18)\n",
      "Cleaned Y.csv           → (4818, 19)\n",
      "Cleaned Z.csv           → (4818, 19)\n",
      "Cleaned RTU_1.csv       → (4871, 34)\n",
      "Cleaned RTU_2.csv       → (4873, 34)\n",
      "Cleaned RTU_3.csv       → (4873, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Columns to drop (as per client's suggestion)\n",
    "columns_to_drop = [\n",
    "    'Air_Flow_Diff', 'Room_Temperature_Diff',\n",
    "    'VAV_Temperature_Diff', 'SaTemp', 'SaTmp', 'oppMode']\n",
    "\n",
    "# Function to forward-fill only setpoint-related columns\n",
    "def forward_fill_setpoints(df):\n",
    "    for col in df.columns:\n",
    "        if \"Sp\" in col:\n",
    "            df[col] = df[col].ffill()\n",
    "    return df\n",
    "\n",
    "# Reusable cleaning function\n",
    "def clean_dataframe_dict(data_dict):\n",
    "    cleaned_data = {}\n",
    "    for filename, df in data_dict.items():\n",
    "        df_cleaned = df.copy()\n",
    "        df_cleaned = forward_fill_setpoints(df_cleaned)\n",
    "        df_cleaned.drop(columns=[col for col in columns_to_drop if col in df_cleaned.columns], inplace=True)\n",
    "        cleaned_data[filename] = df_cleaned\n",
    "        print(f\"Cleaned {filename:<15} → {df_cleaned.shape}\")\n",
    "    return cleaned_data\n",
    "\n",
    "# Apply cleaning\n",
    "cleaned_tu_data = clean_dataframe_dict(tu_data)\n",
    "cleaned_rtu_data = clean_dataframe_dict(rtu_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bd9082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns found across TU files:\n",
      "\n",
      "time            → 47/47 files\n",
      "AirFlow         → 47/47 files\n",
      "ClgPct          → 47/47 files\n",
      "DmprPos         → 47/47 files\n",
      "DschAirTemp     → 47/47 files\n",
      "EffAirflowSp    → 47/47 files\n",
      "EffOcc          → 47/47 files\n",
      "EffSp           → 47/47 files\n",
      "HtgPct          → 47/47 files\n",
      "OccClgSp        → 47/47 files\n",
      "OccCmd          → 47/47 files\n",
      "OccHtgSp        → 47/47 files\n",
      "RmSp            → 47/47 files\n",
      "RmTemp          → 47/47 files\n",
      "StbyClgSp       → 47/47 files\n",
      "StbyHtgSp       → 47/47 files\n",
      "UnoccClgSp      → 47/47 files\n",
      "UnoccHtgSp      → 47/47 files\n",
      "RmCo2           → 27/47 files\n",
      "Cooling_Stg_Cmd → 14/47 files\n",
      "Heating_Stg_Cmd → 14/47 files\n",
      "SuplFanCmd      → 9/47 files\n",
      "SuplFanState    → 9/47 files\n",
      "AirflowSpRht    → 3/47 files\n",
      "\n",
      "Columns with std = 0 in some TU files:\n",
      "\n",
      "EffOcc          → 47 files\n",
      "OccClgSp        → 47 files\n",
      "OccCmd          → 47 files\n",
      "OccHtgSp        → 47 files\n",
      "StbyClgSp       → 47 files\n",
      "StbyHtgSp       → 47 files\n",
      "UnoccClgSp      → 47 files\n",
      "UnoccHtgSp      → 47 files\n",
      "RmSp            → 44 files\n",
      "ClgPct          → 37 files\n",
      "EffSp           → 36 files\n",
      "RmCo2           → 15 files\n",
      "EffAirflowSp    → 14 files\n",
      "Heating_Stg_Cmd → 14 files\n",
      "SuplFanCmd      → 9 files\n",
      "SuplFanState    → 9 files\n",
      "HtgPct          → 5 files\n",
      "AirflowSpRht    → 1 files\n",
      "\n",
      "Global STD, Min, Max for all numeric columns:\n",
      "\n",
      "                     std       min       max\n",
      "EffOcc             0.000     0.000     0.000\n",
      "OccCmd             0.000     0.000     0.000\n",
      "SuplFanCmd         0.000     1.000     1.000\n",
      "SuplFanState       0.000    -1.000    -1.000\n",
      "Heating_Stg_Cmd    0.000     2.000     2.000\n",
      "StbyHtgSp          0.289    68.990    71.000\n",
      "Cooling_Stg_Cmd    0.433     2.000     3.000\n",
      "OccHtgSp           0.526    68.000    73.000\n",
      "OccClgSp           0.824    70.000    75.000\n",
      "RmTemp             1.535    51.870    77.837\n",
      "EffSp              2.442    66.000    82.990\n",
      "UnoccHtgSp         4.670    55.000    68.000\n",
      "StbyClgSp          6.433    64.000    84.000\n",
      "UnoccClgSp         8.119    65.000    85.000\n",
      "DschAirTemp       13.367    51.483   142.380\n",
      "ClgPct            18.709     0.000   100.000\n",
      "DmprPos           30.830     0.000   100.000\n",
      "RmSp              35.326     0.000    75.000\n",
      "HtgPct            40.685     0.000   100.000\n",
      "AirflowSpRht      42.956  1108.170  1199.290\n",
      "RmCo2            148.370     0.000  1289.333\n",
      "AirFlow          313.468     0.000  1903.460\n",
      "EffAirflowSp     432.289    63.570  1875.210\n"
     ]
    }
   ],
   "source": [
    "# Check how many TU files each column appears in\n",
    "column_appearance = defaultdict(set)\n",
    "\n",
    "for filename, df in cleaned_tu_data.items():\n",
    "    for column in df.columns:\n",
    "        column_appearance[column].add(filename)\n",
    "\n",
    "print(\"Columns found across TU files:\\n\")\n",
    "for col in sorted(column_appearance, key=lambda x: -len(column_appearance[x])):\n",
    "    print(f\"{col:<15} → {len(column_appearance[col])}/47 files\")\n",
    "\n",
    "\n",
    "# Count how many TU files have std = 0 for each column\n",
    "zero_std_columns = defaultdict(set)\n",
    "\n",
    "for filename, df in cleaned_tu_data.items():\n",
    "    numeric_cols = df.select_dtypes(include='number')\n",
    "    for col in numeric_cols.columns:\n",
    "        if numeric_cols[col].std() == 0:\n",
    "            zero_std_columns[col].add(filename)\n",
    "\n",
    "print(\"\\nColumns with std = 0 in some TU files:\\n\")\n",
    "for col in sorted(zero_std_columns, key=lambda x: -len(zero_std_columns[x])):\n",
    "    print(f\"{col:<15} → {len(zero_std_columns[col])} files\")\n",
    "\n",
    "\n",
    "# Combine all TU data to check global std, min, max\n",
    "merged_df = pd.concat(\n",
    "    [df.assign(tu_name=name.replace(\".csv\", \"\")) for name, df in cleaned_tu_data.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "global_stats = merged_df.describe().transpose()[['std', 'min', 'max']].sort_values(by='std')\n",
    "\n",
    "print(\"\\nGlobal STD, Min, Max for all numeric columns:\\n\")\n",
    "print(global_stats.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172224cf",
   "metadata": {},
   "source": [
    "\n",
    "**OBSERVATIONS: Columns to Drop:**\n",
    "\n",
    "* EffOcc - Always 0\n",
    "\n",
    "* OccCmd - Always 0\n",
    "\n",
    "* SuplFanCmd - Only in 9 files and always constant\n",
    "\n",
    "* SuplFanState - Only in 9 files and always constant\n",
    "\n",
    "* Heating_Stg_Cmd - Only in 14 files and always constant\n",
    "\n",
    "* Cooling_Stg_Cmd - Only in 14 files with minimal variation\n",
    "\n",
    "* AirflowSpRht - Only in 3 files\n",
    "\n",
    "* RmCo2 - Missing in many files (only in 27/47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad8d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned A.csv           → (4818, 16)\n",
      "Cleaned AA.csv          → (4816, 16)\n",
      "Cleaned B.csv           → (4818, 16)\n",
      "Cleaned BB.csv          → (4816, 16)\n",
      "Cleaned C.csv           → (4818, 16)\n",
      "Cleaned CC.csv          → (4816, 16)\n",
      "Cleaned D.csv           → (4818, 16)\n",
      "Cleaned DD.csv          → (4816, 16)\n",
      "Cleaned E.csv           → (4818, 16)\n",
      "Cleaned EE.csv          → (4816, 16)\n",
      "Cleaned F.csv           → (4818, 16)\n",
      "Cleaned FF.csv          → (4816, 16)\n",
      "Cleaned G.csv           → (4818, 16)\n",
      "Cleaned GG.csv          → (4816, 16)\n",
      "Cleaned H.csv           → (4818, 16)\n",
      "Cleaned HH.csv          → (4816, 16)\n",
      "Cleaned I.csv           → (4818, 16)\n",
      "Cleaned II.csv          → (4816, 16)\n",
      "Cleaned J.csv           → (4818, 16)\n",
      "Cleaned JJ.csv          → (4816, 16)\n",
      "Cleaned K.csv           → (4818, 16)\n",
      "Cleaned KK.csv          → (4816, 16)\n",
      "Cleaned L.csv           → (4818, 16)\n",
      "Cleaned LL.csv          → (4816, 16)\n",
      "Cleaned M.csv           → (4818, 16)\n",
      "Cleaned MM.csv          → (4816, 16)\n",
      "Cleaned N.csv           → (4818, 16)\n",
      "Cleaned NN.csv          → (4816, 16)\n",
      "Cleaned O.csv           → (4818, 16)\n",
      "Cleaned OO.csv          → (4816, 16)\n",
      "Cleaned P.csv           → (4818, 16)\n",
      "Cleaned PP.csv          → (4816, 16)\n",
      "Cleaned Q.csv           → (4818, 16)\n",
      "Cleaned QQ.csv          → (4817, 16)\n",
      "Cleaned R.csv           → (4818, 16)\n",
      "Cleaned RR.csv          → (4818, 16)\n",
      "Cleaned S.csv           → (4818, 16)\n",
      "Cleaned SS.csv          → (4818, 16)\n",
      "Cleaned T.csv           → (4818, 16)\n",
      "Cleaned TT.csv          → (4818, 16)\n",
      "Cleaned U.csv           → (4818, 16)\n",
      "Cleaned UU.csv          → (4818, 16)\n",
      "Cleaned V.csv           → (4818, 16)\n",
      "Cleaned W.csv           → (4818, 16)\n",
      "Cleaned X.csv           → (4818, 16)\n",
      "Cleaned Y.csv           → (4818, 16)\n",
      "Cleaned Z.csv           → (4818, 16)\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    'EffOcc','OccCmd','SuplFanCmd','SuplFanState','Heating_Stg_Cmd','Cooling_Stg_Cmd', 'AirflowSpRht', 'RmCo2'\n",
    "]\n",
    "\n",
    "for file, df in cleaned_tu_data.items():\n",
    "    # Drop columns only if they exist in that file\n",
    "    df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
    "    print(f\"Cleaned {file:<15} → {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f40872f",
   "metadata": {},
   "source": [
    "* Check for Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a52551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File            |    Missing rows\n",
      "A.csv           |             248\n",
      "AA.csv          |             247\n",
      "B.csv           |             248\n",
      "BB.csv          |            4492\n",
      "C.csv           |             248\n",
      "CC.csv          |             247\n",
      "D.csv           |            4498\n",
      "DD.csv          |             247\n",
      "E.csv           |             248\n",
      "EE.csv          |             247\n",
      "F.csv           |             248\n",
      "FF.csv          |             247\n",
      "G.csv           |             248\n",
      "GG.csv          |             247\n",
      "H.csv           |             248\n",
      "HH.csv          |             247\n",
      "I.csv           |             248\n",
      "II.csv          |             247\n",
      "J.csv           |             248\n",
      "JJ.csv          |             247\n",
      "K.csv           |             248\n",
      "KK.csv          |             247\n",
      "L.csv           |             248\n",
      "LL.csv          |             247\n",
      "M.csv           |             248\n",
      "MM.csv          |             247\n",
      "N.csv           |             248\n",
      "NN.csv          |             247\n",
      "O.csv           |             248\n",
      "OO.csv          |             247\n",
      "P.csv           |             248\n",
      "PP.csv          |             247\n",
      "Q.csv           |             248\n",
      "QQ.csv          |             248\n",
      "R.csv           |             248\n",
      "RR.csv          |             249\n",
      "S.csv           |             248\n",
      "SS.csv          |             248\n",
      "T.csv           |             248\n",
      "TT.csv          |             248\n",
      "U.csv           |             248\n",
      "UU.csv          |             248\n",
      "V.csv           |             248\n",
      "W.csv           |             248\n",
      "X.csv           |             248\n",
      "Y.csv           |             248\n",
      "Z.csv           |             248\n",
      "\n",
      "File            |    Missing rows\n",
      "RTU_1.csv       |             226\n",
      "RTU_2.csv       |             225\n",
      "RTU_3.csv       |             225\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows in each file contain missing values\n",
    "def check_missing_rows(data_dict, label=\"TU\"):\n",
    "    print(f\"\\n{'File':<15} | {'Missing rows':>15}\")   \n",
    "    for file, df in data_dict.items():\n",
    "        missing = df.isnull().any(axis=1).sum()\n",
    "        print(f\"{file:<15} | {missing:>15}\")\n",
    "\n",
    "check_missing_rows(cleaned_tu_data, label=\"TU\")\n",
    "check_missing_rows(cleaned_rtu_data, label=\"RTU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35444a8b",
   "metadata": {},
   "source": [
    "We will take a max threshold of 250 and delete rows with NaNs if ≤ 250 rows are affected.\n",
    "\n",
    "Files BB.csv and D.csv have 4492 and 4498 rows with NaNs, so for now, we will exclude those files from deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae3175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File            |    Missing rows\n",
      "A.csv           |               0\n",
      "AA.csv          |               0\n",
      "B.csv           |               0\n",
      "BB.csv          |            4492\n",
      "C.csv           |               0\n",
      "CC.csv          |               0\n",
      "D.csv           |            4498\n",
      "DD.csv          |               0\n",
      "E.csv           |               0\n",
      "EE.csv          |               0\n",
      "F.csv           |               0\n",
      "FF.csv          |               0\n",
      "G.csv           |               0\n",
      "GG.csv          |               0\n",
      "H.csv           |               0\n",
      "HH.csv          |               0\n",
      "I.csv           |               0\n",
      "II.csv          |               0\n",
      "J.csv           |               0\n",
      "JJ.csv          |               0\n",
      "K.csv           |               0\n",
      "KK.csv          |               0\n",
      "L.csv           |               0\n",
      "LL.csv          |               0\n",
      "M.csv           |               0\n",
      "MM.csv          |               0\n",
      "N.csv           |               0\n",
      "NN.csv          |               0\n",
      "O.csv           |               0\n",
      "OO.csv          |               0\n",
      "P.csv           |               0\n",
      "PP.csv          |               0\n",
      "Q.csv           |               0\n",
      "QQ.csv          |               0\n",
      "R.csv           |               0\n",
      "RR.csv          |               0\n",
      "S.csv           |               0\n",
      "SS.csv          |               0\n",
      "T.csv           |               0\n",
      "TT.csv          |               0\n",
      "U.csv           |               0\n",
      "UU.csv          |               0\n",
      "V.csv           |               0\n",
      "W.csv           |               0\n",
      "X.csv           |               0\n",
      "Y.csv           |               0\n",
      "Z.csv           |               0\n",
      "\n",
      "File            |    Missing rows\n",
      "RTU_1.csv       |               0\n",
      "RTU_2.csv       |               0\n",
      "RTU_3.csv       |               0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaNs only if ≤ 250 rows are affected\n",
    "max = 250\n",
    "\n",
    "def drop_missing(data_dict):    \n",
    "    for file, df in data_dict.items():\n",
    "        nan_rows = df.isnull().any(axis=1)\n",
    "        nan_count = nan_rows.sum()\n",
    "        \n",
    "        if nan_count <= max:\n",
    "            data_dict[file] = df[~nan_rows]\n",
    "\n",
    "def save_to_csv(data_dict, folder_path):\n",
    "    for file, df in data_dict.items():\n",
    "        df.to_csv(os.path.join(folder_path, file), index=False)\n",
    "\n",
    "drop_missing(cleaned_tu_data)\n",
    "check_missing_rows(cleaned_tu_data, label=\"TU\")\n",
    "save_to_csv(cleaned_tu_data, \"cleaned_data/cleaned_TUs/\")\n",
    "\n",
    "drop_missing(cleaned_rtu_data)\n",
    "check_missing_rows(cleaned_rtu_data, label=\"RTU\")\n",
    "save_to_csv(cleaned_rtu_data, \"cleaned_data/cleaned_RTUs/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b9081",
   "metadata": {},
   "source": [
    "Now we will keep only the rows with timestamps that are present in all RTU and TU files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d8795d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Common Timestamps: 4568\n",
      "\n",
      "Synced TU: A.csv           → (4568, 16)\n",
      "Synced TU: AA.csv          → (4568, 16)\n",
      "Synced TU: B.csv           → (4568, 16)\n",
      "Synced TU: BB.csv          → (4568, 16)\n",
      "Synced TU: C.csv           → (4568, 16)\n",
      "Synced TU: CC.csv          → (4568, 16)\n",
      "Synced TU: D.csv           → (4568, 16)\n",
      "Synced TU: DD.csv          → (4568, 16)\n",
      "Synced TU: E.csv           → (4568, 16)\n",
      "Synced TU: EE.csv          → (4568, 16)\n",
      "Synced TU: F.csv           → (4568, 16)\n",
      "Synced TU: FF.csv          → (4568, 16)\n",
      "Synced TU: G.csv           → (4568, 16)\n",
      "Synced TU: GG.csv          → (4568, 16)\n",
      "Synced TU: H.csv           → (4568, 16)\n",
      "Synced TU: HH.csv          → (4568, 16)\n",
      "Synced TU: I.csv           → (4568, 16)\n",
      "Synced TU: II.csv          → (4568, 16)\n",
      "Synced TU: J.csv           → (4568, 16)\n",
      "Synced TU: JJ.csv          → (4568, 16)\n",
      "Synced TU: K.csv           → (4568, 16)\n",
      "Synced TU: KK.csv          → (4568, 16)\n",
      "Synced TU: L.csv           → (4568, 16)\n",
      "Synced TU: LL.csv          → (4568, 16)\n",
      "Synced TU: M.csv           → (4568, 16)\n",
      "Synced TU: MM.csv          → (4568, 16)\n",
      "Synced TU: N.csv           → (4568, 16)\n",
      "Synced TU: NN.csv          → (4568, 16)\n",
      "Synced TU: O.csv           → (4568, 16)\n",
      "Synced TU: OO.csv          → (4568, 16)\n",
      "Synced TU: P.csv           → (4568, 16)\n",
      "Synced TU: PP.csv          → (4568, 16)\n",
      "Synced TU: Q.csv           → (4568, 16)\n",
      "Synced TU: QQ.csv          → (4568, 16)\n",
      "Synced TU: R.csv           → (4568, 16)\n",
      "Synced TU: RR.csv          → (4568, 16)\n",
      "Synced TU: S.csv           → (4568, 16)\n",
      "Synced TU: SS.csv          → (4568, 16)\n",
      "Synced TU: T.csv           → (4568, 16)\n",
      "Synced TU: TT.csv          → (4568, 16)\n",
      "Synced TU: U.csv           → (4568, 16)\n",
      "Synced TU: UU.csv          → (4568, 16)\n",
      "Synced TU: V.csv           → (4568, 16)\n",
      "Synced TU: W.csv           → (4568, 16)\n",
      "Synced TU: X.csv           → (4568, 16)\n",
      "Synced TU: Y.csv           → (4568, 16)\n",
      "Synced TU: Z.csv           → (4568, 16)\n",
      "Synced RTU: RTU_1.csv       → (4568, 34)\n",
      "Synced RTU: RTU_2.csv       → (4568, 34)\n",
      "Synced RTU: RTU_3.csv       → (4568, 21)\n"
     ]
    }
   ],
   "source": [
    "# Output folders\n",
    "synced_tu_folder = \"cleaned_data/cleaned_TUs_synced\"\n",
    "synced_rtu_folder = \"cleaned_data/cleaned_RTUs_synced\"\n",
    "os.makedirs(synced_tu_folder, exist_ok=True)\n",
    "os.makedirs(synced_rtu_folder, exist_ok=True)\n",
    "\n",
    "# Find common timestamps across all TU and RTU files\n",
    "tu_times = [set(df['time']) for df in cleaned_tu_data.values() if 'time' in df.columns]\n",
    "rtu_times = [set(df['time']) for df in cleaned_rtu_data.values() if 'time' in df.columns]\n",
    "common_timestamps = sorted(reduce(lambda a, b: a & b, tu_times + rtu_times))\n",
    "print(f\"\\nTotal Common Timestamps: {len(common_timestamps)}\\n\")\n",
    "\n",
    "# Create dictionaries to store synchronized dataframes\n",
    "synced_tu_data = {}\n",
    "synced_rtu_data = {}\n",
    "\n",
    "# Sync and save TU files\n",
    "for file, df in cleaned_tu_data.items():\n",
    "    if 'time' in df.columns:\n",
    "        df_synced = df[df['time'].isin(common_timestamps)].sort_values(by='time')\n",
    "        synced_tu_data[file] = df_synced\n",
    "        df_synced.to_csv(os.path.join(synced_tu_folder, file), index=False)\n",
    "        print(f\"Synced TU: {file:<15} → {df_synced.shape}\")\n",
    "\n",
    "# Sync and save RTU files\n",
    "for file, df in cleaned_rtu_data.items():\n",
    "    if 'time' in df.columns:\n",
    "        df_synced = df[df['time'].isin(common_timestamps)].sort_values(by='time')\n",
    "        synced_rtu_data[file] = df_synced\n",
    "        df_synced.to_csv(os.path.join(synced_rtu_folder, file), index=False)\n",
    "        print(f\"Synced RTU: {file:<15} → {df_synced.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
